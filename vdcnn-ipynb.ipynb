{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Julius/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### Package Import\n",
    "import vdcnn\n",
    "import pandas as pd\n",
    "from utils import CharEmbeddedEncoder\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import gc\n",
    "from os import makedirs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, BatchNormalization, Activation, Dense, Lambda, Dropout\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Function Definition\n",
    "def to_categorical(y, nb_classes=None):\n",
    "    y = np.asarray(y, dtype='int32')\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y) + 1\n",
    "    Y = np.zeros((len(y), nb_classes))\n",
    "    for i in range(len(y)):\n",
    "        Y[i, y[i]] = 1.\n",
    "    return Y\n",
    "\n",
    "def _top_k(x):\n",
    "    x = tf.transpose(x, [0, 2, 1])\n",
    "    k_max = tf.nn.top_k(x, k=top_k)\n",
    "    return tf.reshape(k_max[0], (-1, num_filters[-1] * top_k))\n",
    "\n",
    "def create_model(num_classes, num_filters=[64, 128, 256, 512], top_k=3, learning_rate=0.01, input_dim=69):\n",
    "    \"\"\"\n",
    "    Create VDCNN Model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=69, output_dim=16, input_length=1014, name='input_embedding'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    \n",
    "    for i in range(len(num_filters)):\n",
    "        conv_filter= num_filters[i]\n",
    "        \"\"\"\n",
    "        Build Convolutional Block\n",
    "        \"\"\"\n",
    "        conv_block = Sequential()\n",
    "        conv_block.add(Conv1D(filters=conv_filter, \n",
    "                              kernel_size=3, \n",
    "                              strides=1, \n",
    "                              padding='same', \n",
    "                              input_shape=list(model.get_output_shape_at(0))[1:]))\n",
    "        conv_block.add(BatchNormalization())\n",
    "        conv_block.add(Activation('relu'))\n",
    "        conv_block.add(Conv1D(filters=conv_filter, \n",
    "                              kernel_size=3, \n",
    "                              strides=1, \n",
    "                              padding='same'))\n",
    "        conv_block.add(BatchNormalization())\n",
    "        conv_block.add(Activation('relu'))\n",
    "        \n",
    "        model.add(conv_block)\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=2, padding=\"same\"))\n",
    "    \n",
    "    model.add(Lambda(_top_k, output_shape=(num_filters[-1] * top_k,)))\n",
    "    model.add(Dense(2048, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2, seed=23))\n",
    "    model.add(Dense(2048, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2, seed=23))\n",
    "    model.add(Dense(num_classes, activation='softmax', name='output_layer'))\n",
    "    sgd = SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=False)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=sgd, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Class  Definition\n",
    "class CharEmbeddedEncoder:\n",
    "    \"\"\"\n",
    "    An encoder for character embedding based on \"Text Understanding from Scratch\"\n",
    "        URL: https://arxiv.org/pdf/1502.01710.pdf\n",
    "    \"\"\"\n",
    "    np = __import__('numpy')\n",
    "    mp = __import__('multiprocessing')\n",
    "    def __init__(self, n_jobs=2, sequence_max_length=1014):\n",
    "        self.alphabet =  'abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:\\'\"/|_#$%^&*~`+=<>()[]{}\\\\ \\n'\n",
    "        self.char_dict = {}\n",
    "        self.sequence_max_length = sequence_max_length\n",
    "        self.n_jobs = n_jobs\n",
    "        for i,c in enumerate(self.alphabet):\n",
    "            self.char_dict[c] = i\n",
    "        self.char_dict_len = len(self.char_dict)+1\n",
    "                          \n",
    "    def char2vec(self, text):\n",
    "        data = self.np.ones(self.sequence_max_length) * self.char_dict_len\n",
    "        for i in range(len(text)):\n",
    "            if text[i] in self.char_dict:\n",
    "                data[i] = self.char_dict[text[i]]\n",
    "            else:\n",
    "                data[i] = self.char_dict_len - 1\n",
    "            if i > self.sequence_max_length:\n",
    "                return data\n",
    "        return data\n",
    "    \n",
    "    def transform(self, documents):\n",
    "        char_vecs = []\n",
    "        for document in documents:\n",
    "            char_vecs.append(self.char2vec(document))\n",
    "        return self.np.asarray(char_vecs, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Global Variable Declaration\n",
    "random_seed = 23\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare Data consume:0:00:17.636716\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_embedding (Embedding)  (None, 1014, 16)          1104      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 507, 64)           3136      \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 507, 64)           25216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 254, 64)           0         \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 254, 128)          75008     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 127, 128)          0         \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 127, 256)          297472    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 64, 256)           0         \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 64, 512)           1184768   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 32, 512)           0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              3147776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 8,939,028\n",
      "Trainable params: 8,935,188\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_embedding (Embedding)  (None, 1014, 16)          1104      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 507, 64)           3136      \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 507, 64)           25216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 254, 64)           0         \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 254, 128)          75008     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 127, 128)          0         \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 127, 256)          297472    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 64, 256)           0         \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 64, 512)           1184768   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 32, 512)           0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              3147776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 8,939,028\n",
      "Trainable params: 8,935,188\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[0,0] = 69 is not in [0, 69)\n\t [[Node: input_embedding/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_embedding/embeddings/read, input_embedding/Cast)]]\n\nCaused by op 'input_embedding/Gather', defined at:\n  File \"/Users/Julius/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/Julius/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-ba512874309d>\", line 22, in <module>\n    model = vdcnn.create_model(num_classes=num_classes, input_dim=encoder.char_dict_len)\n  File \"/Users/Julius/git_repo/vdcnn-keras/vdcnn.py\", line 10, in create_model\n    model.add(Embedding(input_dim=69, output_dim=16, input_length=1014, name='input_embedding'))\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/keras/models.py\", line 467, in add\n    layer(x)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1208, in gather\n    return tf.gather(reference, indices)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2486, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1834, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[0,0] = 69 is not in [0, 69)\n\t [[Node: input_embedding/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_embedding/embeddings/read, input_embedding/Cast)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[0,0] = 69 is not in [0, 69)\n\t [[Node: input_embedding/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_embedding/embeddings/read, input_embedding/Cast)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ba512874309d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mbatch_train_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mend_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mbatch_train_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mend_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mrtn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_train_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_train_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrtn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrtn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m   1068\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1847\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1849\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[0,0] = 69 is not in [0, 69)\n\t [[Node: input_embedding/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_embedding/embeddings/read, input_embedding/Cast)]]\n\nCaused by op 'input_embedding/Gather', defined at:\n  File \"/Users/Julius/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/Julius/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-ba512874309d>\", line 22, in <module>\n    model = vdcnn.create_model(num_classes=num_classes, input_dim=encoder.char_dict_len)\n  File \"/Users/Julius/git_repo/vdcnn-keras/vdcnn.py\", line 10, in create_model\n    model.add(Embedding(input_dim=69, output_dim=16, input_length=1014, name='input_embedding'))\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/keras/models.py\", line 467, in add\n    layer(x)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1208, in gather\n    return tf.gather(reference, indices)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2486, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1834, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/Julius/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[0,0] = 69 is not in [0, 69)\n\t [[Node: input_embedding/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_embedding/embeddings/read, input_embedding/Cast)]]\n"
     ]
    }
   ],
   "source": [
    "### Main Procedure\n",
    "s = dt.now()\n",
    "train_data = pd.read_csv('data/ag_news_csv/train.csv', index_col=False, header=None, names=['class', 'title', 'content'])\n",
    "test_data = pd.read_csv('data/ag_news_csv/test.csv', index_col=False, header=None, names=['class', 'title', 'content'])\n",
    "f = open('data/ag_news_csv/classes.txt', 'r')\n",
    "classes = [i.replace('\\n','') for i in list(f)]\n",
    "num_classes = len(classes)\n",
    "f.close()\n",
    "encoder = CharEmbeddedEncoder(n_jobs=4)\n",
    "train_X = encoder.transform(train_data['content'].as_matrix())\n",
    "train_data['class'] = train_data['class']-1\n",
    "train_Y = train_data['class'].as_matrix()\n",
    "train_Y = to_categorical(train_Y, nb_classes=num_classes)\n",
    "\n",
    "test_X = encoder.transform(test_data['content'].as_matrix())\n",
    "test_data['class'] = test_data['class']-1\n",
    "test_Y = test_data['class'].as_matrix()\n",
    "e = dt.now()\n",
    "p = e - s\n",
    "print('Prepare Data consume:{}'.format(p))\n",
    "\n",
    "model = vdcnn.create_model(num_classes=num_classes, input_dim=encoder.char_dict_len)\n",
    "model.summary()\n",
    "\n",
    "makedirs('model', exist_ok=True)\n",
    "makedirs('figure', exist_ok=True)\n",
    "makedirs('performance', exist_ok=True)\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "epoch = 1\n",
    "threshold = 0.95\n",
    "acc_of_epoch = 0.0\n",
    "while acc_of_epoch < threshold:\n",
    "    shuffle_index = [i for i in range(len(train_X))]\n",
    "    random.seed = random_seed + epoch\n",
    "    random.shuffle(shuffle_index)\n",
    "\n",
    "    tmp = []\n",
    "    for i in range(len(train_X)):\n",
    "        tmp.append(train_X[shuffle_index[i]])\n",
    "    train_X = np.asarray(tmp)\n",
    "\n",
    "    tmp = []\n",
    "    for i in range(len(train_Y)):\n",
    "        tmp.append(train_Y[shuffle_index[i]])\n",
    "    train_Y = np.asarray(tmp)\n",
    "    del(tmp)\n",
    "\n",
    "    loss_of_epoch = []\n",
    "    acc_of_epoch = []\n",
    "    for start_index in range(0, len(train_X), batch_size):\n",
    "        end_index = start_index + batch_size\n",
    "        if end_index > len(train_X):\n",
    "            end_index = len(train_X)\n",
    "        batch_train_X = train_X[start_index: end_index]\n",
    "        batch_train_Y = train_Y[start_index: end_index]\n",
    "        rtn = model.train_on_batch(x=batch_train_X, y=batch_train_Y)\n",
    "        loss = rtn[0]\n",
    "        acc = rtn[1]\n",
    "        loss_of_epoch.append(loss)\n",
    "        acc_of_epoch.append(acc)\n",
    "        del(batch_train_X)\n",
    "        del(batch_train_Y)\n",
    "        gc.collect()\n",
    "    loss_of_epoch = np.mean(loss_of_epoch)\n",
    "    acc_of_epoch = np.mean(acc_of_epoch)\n",
    "    losses.append(loss_of_epoch)\n",
    "    accuracies.append(acc_of_epoch)\n",
    "    print('Epoch {} completed, loss - {}, acc - {}'.format(epoch, loss_of_epoch, acc_of_epoch))\n",
    "    break\n",
    "    if epoch % 10 == 0:\n",
    "        model.save('model/ag_news_shuffle_e{}.mdl'.format(epoch))\n",
    "        plt.plot(losses)\n",
    "        plt.savefig('figure/loss_e{}.png'.format(epoch))\n",
    "        plt.close('all')\n",
    "        plt.clf()\n",
    "        plt.plot(accuracies)\n",
    "        plt.savefig('figure/accuracy_e{}.png'.format(epoch))\n",
    "        plt.close('all')\n",
    "        plt.clf()\n",
    "    epoch += 1\n",
    "e = dt.now()\n",
    "p = e - s\n",
    "print('Training Model consume:{}'.format(p))\n",
    "\n",
    "model.save('model/ag_news_shuffle_e{}.mdl'.format(epoch))\n",
    "\n",
    "s = dt.now()\n",
    "predict_Y = model.predict_classes(test_X)\n",
    "e = dt.now()\n",
    "p = e - s\n",
    "print('Predict consume:{}'.format(p))\n",
    "\n",
    "print(confusion_matrix(test_Y, predict_Y))\n",
    "pd.DataFrame(confusion_matrix(test_Y, predict_Y)).to_csv('performance/ag_news_shuffle.csv')\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.savefig('figure/loss.png')\n",
    "plt.close('all')\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(accuracies)\n",
    "plt.savefig('figure/accuracy.png')\n",
    "plt.close('all')\n",
    "plt.clf()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
